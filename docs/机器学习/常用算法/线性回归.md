<div align="center"><img src="https://gitee.com/struggle3014/picBed/raw/master/name_code.png"></div>

# 导读

本文介绍线性回归（Linear Regression）算法。

***持续更新中~***



# 目录

<nav>
<a href='#导读' style='text-decoration:none;font-weight:bolder'>导读</a><br/>
<a href='#目录' style='text-decoration:none;font-weight:bolder'>目录</a><br/>
<a href='#正文' style='text-decoration:none;font-weight:bolder'>正文</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;<a href='#1 模型表示' style='text-decoration:none;${border-style}'>1 模型表示</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;<a href='#2 代价函数' style='text-decoration:none;${border-style}'>2 代价函数</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;<a href='#3 代价函数的直观理解' style='text-decoration:none;${border-style}'>3 代价函数的直观理解</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;<a href='#4 梯度下降' style='text-decoration:none;${border-style}'>4 梯度下降</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;<a href='#5 梯度下降的直观理解' style='text-decoration:none;${border-style}'>5 梯度下降的直观理解</a><br/>
<a href='#总结' style='text-decoration:none;font-weight:bolder'>总结</a><br/>
<a href='#参考文献' style='text-decoration:none;font-weight:bolder'>参考文献</a><br/>
</nav>

# 正文

## 1 模型表示

由预测房屋住房价格的监督学习过程引出线性回归模型。

假设存在一数据集，该数据集包含某市的住房价格。在这里，根据房屋尺寸所售出的价格，画出数据集。例如，如果你朋友的房子是1250平方尺大小，你要告诉他这个房子能卖多少钱。那么，你可以构建一个模型，也许是这条直线，从该数据模型上，告诉你的朋友，他大约能以220000（美元）左右的价格卖掉房子。这就是监督学习算法的例子。

![监督学习（房屋价格预测模型）](https://gitee.com/struggle3014/picBed/raw/master/监督学习（房屋价格预测模型）.png)

<div align="center"><font size="2">监督学习（房屋价格预测模型）</font></div>

上述案例被称为**监督学习**是因为对于每个数据来说，我们都给出了“正确的答案”，这是一个**回归问题**，即根据之前的数据预测一个准确的输出值。同时，还有一类常见的监督学习方式，叫做**分类问题**，预测离散的输出值，例如确定癌症的良性或恶性。

在监督学习中，我们有一个数据集，该数据集被成为**训练集（Training Set）**。以房屋交易问题为例，假设我们回归问题的训练集如下所示：

| 英尺大小（x） | 价格以1000$为单位（y） |
| ------------- | ---------------------- |
| 2104          | 460                    |
| 1416          | 232                    |
| 1534          | 315                    |
| ...           | ...                    |

该回归问题标记如下：

| 标记                                                         | 含义                                               |
| ------------------------------------------------------------ | -------------------------------------------------- |
| m                                                            | 训练集中实例的数量                                 |
| x                                                            | 特征/输出变量                                      |
| y                                                            | 目标变量/输出变量                                  |
| (x, y)                                                       | 训练集中的实例                                     |
| <img src="http://latex.codecogs.com/svg.latex?(x^{(i)}, y^{(i)})"> | 第 i 个观测实例                                    |
| h                                                            | 学习算法的解决方案或函数，也称为假设（hypothesis） |

![监督学习的工作方式](https://gitee.com/struggle3014/picBed/raw/master/监督学习的工作方式.png)

<div align="center"><font size="2">监督学习算法的工作方式</font></div>

我们的训练集（Training Set）喂给了我们的学习算法，学习算法工作完输出一个函数，用 h 表示。h 代表 hypothesis（假设），h 是从 x 到 y 的函数映射。

对于房价预测问题，如何表达 h？可能的表达方式为：<img src="http://latex.codecogs.com/svg.latex?h_{\theta}(x) = \theta_{0} + \theta_{1}x">



## 2 代价函数

假设我们的学习算法的形式为：<img src="http://latex.codecogs.com/svg.latex?h_{\theta}(x) = \theta_{0} + \theta_{1}x">，如何为模型选择合适的**参数（parameter）**<img src="http://latex.codecogs.com/svg.latex?\theta_{0}">和<img src="http://latex.codecogs.com/svg.latex?\theta_{1}">，在房价问题的例子中分别对应直线的斜率和 y 轴的截距。

参数（parameter）<img src="http://latex.codecogs.com/svg.latex?\theta_{0}">和<img src="http://latex.codecogs.com/svg.latex?\theta_{1}">决定了训练的直线对于训练集的准确程度，模型预测值和实际值之间的差距是**建模误差（modeling error）**。

![建模误差图例](https://gitee.com/struggle3014/picBed/raw/master/建模误差图例.png)

<div align="center"><font size="2">建模误差图例</font></div>

我们的目标是选择可以使得**建模误差平方和最小**的模型参数，即**代价函数**：<img src="http://latex.codecogs.com/svg.latex?J(\theta_{0},\theta_{1}) = \frac{1}{2m}\sum_{i=1}^m(h_{\theta}(x^{(i)})-(y^{(i)}))"> 最小。

我们绘制一个等高图，三个坐标分别为 <img src="http://latex.codecogs.com/svg.latex?\theta_{0}"> 和 <img src="http://latex.codecogs.com/svg.latex?\theta_{1}"> 和 <img src="http://latex.codecogs.com/svg.latex?J(\theta_{0},\theta_{1})">：

![损失函数等高线](https://gitee.com/struggle3014/picBed/raw/master/损失函数等高线.png)

<div align="center"><font size="2">损失函数等高线</font></div>

则可以看出在三维空间中存在一个使得 <img src="http://latex.codecogs.com/svg.latex?J(\theta_{0},\theta_{1})"> 最小的点。

代价函数也被成为平方误差函数，也称为平方误差代价函数。平方误差代价函数式解决回归问题最常用的手段。



## 3 代价函数的直观理解



## 4 梯度下降



## 5 梯度下降的直观理解





# 总结



# 参考文献

[1] [吴恩达机器学习视频教程笔记](https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes)